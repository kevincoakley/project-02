{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../results/image_classification/\"\n",
    "results_column = \"test_accuracy\"\n",
    "round_digits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_by_model_and_dataset = [\n",
    "    # EX1\n",
    "    [\n",
    "        \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet110-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTS8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTB8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet110-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTS8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTB8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    # EX2\n",
    "    [\n",
    "        \"ResNet18-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet50-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet101-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        \"ResNet18-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet50-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet101-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "    ],\n",
    "    # EX3\n",
    "    [\n",
    "        \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet110-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet20-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        \"ResNet56-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        \"ResNet110-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "    ],\n",
    "    [\n",
    "        \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet110-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        \"ResNet20-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        \"ResNet56-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        \"ResNet110-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cvar(dataset, alpha):\n",
    "    # alpha = 0.1 = 90% \n",
    "    # alpha = 0.05 = 95%\n",
    "    # alpha = 0.01 = 99%    \n",
    "\n",
    "    dataset.sort()\n",
    "    var = np.quantile(dataset, alpha)\n",
    "    cvar = dataset[dataset <= var].mean().round(round_digits)\n",
    "    return(cvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kde(data, title):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    sns.histplot(\n",
    "        data,\n",
    "        kde=True,\n",
    "        stat=\"proportion\",\n",
    "        kde_kws=dict(cut=3),\n",
    "        legend=True,\n",
    "    )\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(title.replace(\":\", \"\").replace(\" \",  \"_\") + \"_kde.png\", pad_inches=0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cvar(data, title):\n",
    "\n",
    "    # Calculate the min and max values for the x-axis\n",
    "    min = 0\n",
    "    max = 0\n",
    "\n",
    "    for run_name in data:\n",
    "        run_min = data[run_name].min()\n",
    "        run_max = data[run_name].max()\n",
    "    \n",
    "        if run_min < min or min == 0:\n",
    "            min = run_min\n",
    "        if run_max > max or max == 100:\n",
    "            max = run_max\n",
    "\n",
    "    min = min - (min * 0.01)\n",
    "    max = max + (max * 0.01)\n",
    "\n",
    "    # Set the number of columns and rows for the subplots\n",
    "    # 2 columns and as many rows as needed to fit all the data\n",
    "    ncols = 2\n",
    "    nrows = math.ceil((len(data) / ncols))\n",
    "\n",
    "    if nrows == 1:\n",
    "        nrows = 2\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "    fig.tight_layout(pad=3)\n",
    "\n",
    "    for idx, run_name in enumerate(data):\n",
    "        # Find the row and column for the current plot\n",
    "        column = idx % ncols\n",
    "        row = idx // ncols\n",
    "\n",
    "        # Calculate the summary statistics\n",
    "        dataset_mean = data[run_name].mean()\n",
    "        cvar_95 = calculate_cvar(data[run_name], 0.05)\n",
    "\n",
    "        sns.histplot(\n",
    "            data[run_name],\n",
    "            kde=True,\n",
    "            kde_kws=dict(cut=3),\n",
    "            legend=True,\n",
    "            ax=ax[row, column],\n",
    "        ).set_title(run_name)\n",
    "\n",
    "        # Add the mean and CVaR to the plot\n",
    "        ax[row, column].axvline(dataset_mean, color='red', linestyle='solid', label=\"Mean: %.2f%% \" % (dataset_mean *100) )\n",
    "        ax[row, column].axvline(cvar_95, color='red', linestyle='dashed', label=\"CVaR: %.2f%% \" % (cvar_95 *100)  )\n",
    "\n",
    "        ax[row, column].set(ylabel='')\n",
    "        ax[row, column].tick_params(left=False, bottom=True)\n",
    "        ax[row, column].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax[row, column].legend()\n",
    "        ax[row, column].set(xlabel=\"Accuracy\")\n",
    "        ax[row, column].set_xlim([min, max])\n",
    "        ax[row, column].set_ylim([0, 30])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(title.replace(\":\", \"\").replace(\" \",  \"_\") + \"_cvar.png\", pad_inches=0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary statistics so they can be saved to a CSV file\n",
    "summary_statistics = []\n",
    "\n",
    "for idx, experiments in enumerate(experiments_by_model_and_dataset):\n",
    "\n",
    "    # Set title\n",
    "    # EX1 is the first 4 experiments, EX2 is the next 6, EX3 is the last 2\n",
    "    if idx in [0, 1, 2, 3]:\n",
    "        title = \"EX1:\"\n",
    "    elif idx in [4, 5, 6, 7, 8, 9]:\n",
    "        title = \"EX2:\"\n",
    "    elif idx in [10, 11]:\n",
    "        title = \"EX3:\"\n",
    "\n",
    "    # Include model in title\n",
    "    if \"resnet\" in experiments[0].lower():\n",
    "        title += \" ResNet\"\n",
    "    elif \"vit\" in experiments[0].lower():\n",
    "        title += \" ViT\"\n",
    "\n",
    "    # Save the individual results for the plots\n",
    "    results_values = {}\n",
    "\n",
    "    # Loop through the individual experiments\n",
    "    for experiment in experiments:\n",
    "        df = pd.read_csv(base_directory + experiment)\n",
    "\n",
    "        # Get the 100 results\n",
    "        results = df[results_column].values\n",
    "        # Calculate the summary statistics\n",
    "        mean = np.mean(results).round(round_digits)\n",
    "        median = np.median(results).round(round_digits)\n",
    "        min = np.min(results).round(round_digits)\n",
    "        max = np.max(results).round(round_digits)\n",
    "        std = np.std(results).round(round_digits)\n",
    "        cvar_95 = calculate_cvar(results, 0.05)\n",
    "        skewness = skew(results).round(round_digits)\n",
    "\n",
    "        # Get the model and dataset from the experiment name\n",
    "        dataset = experiment.split(\"-\")[1]\n",
    "        model = experiment.split(\"-\")[0]\n",
    "\n",
    "        # Add the dataset to the title if it is not already there\n",
    "        if dataset not in title:\n",
    "            title = title + \" \" + dataset\n",
    "\n",
    "        # Add whether the model is pretrained or not for the ViT 16 models\n",
    "        if \"vit\" in model.lower() and \"16\" in model.lower():\n",
    "            if \"pretrained\" in experiment:\n",
    "                model += \" (Pretrained)\"\n",
    "            else:\n",
    "                model += \" (Random)\"\n",
    "\n",
    "        # Add whether the model is TensorFlow or PyTorch for the EX3 experiments\n",
    "        if \"ex3\" in title.lower():\n",
    "            if \"tensorflow\" in experiment.lower():\n",
    "                model += \" (TensorFlow)\"\n",
    "            else:\n",
    "                model += \" (PyTorch)\"\n",
    "\n",
    "        # Save the results for the plot\n",
    "        results_values[model] = results\n",
    "\n",
    "        # Save the summary statistics\n",
    "        summary_statistics.append([dataset, model, mean, median, min, max, std, cvar_95, skewness])\n",
    "\n",
    "    # Plot the results for the experiment as a KDE histogram\n",
    "    save_kde(results_values, title)\n",
    "    # Plot the results for the experiment as a CVaR histogram\n",
    "    save_cvar(results_values, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_df = pd.DataFrame(summary_statistics, columns=[\"Dataset\", \"Model\", \"Mean\", \"Median\", \"Min\", \"Max\", \"Std\", \"CVaR 95%\", \"Skewness\"])\n",
    "summary_statistics_df.to_csv(\"image_summary_statistics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
