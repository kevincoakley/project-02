{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis, variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../results/image_classification/\"\n",
    "results_column = \"test_accuracy\"\n",
    "round_digits = 4\n",
    "cvar_alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_by_model_and_dataset = [\n",
    "    # EX1 - Small Image Classification\n",
    "    [\n",
    "        [\n",
    "            \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTS8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTS8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # EX2 - Large Image Classification\n",
    "    [\n",
    "        [\n",
    "            \"ResNet18-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet50-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet101-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        ],\n",
    "\n",
    "        [\n",
    "            \"ResNet18-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet50-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet101-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # EX3 - Learning Rate Warmup Comparison\n",
    "    [\n",
    "        [\n",
    "            \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"learning_rate/ResNet20LR-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"learning_rate/ResNet56LR-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"learning_rate/ResNet20LR-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"learning_rate/ResNet56LR-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # EX4 - Random train/val/test splits\n",
    "    [\n",
    "        [\n",
    "            \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_01-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_02-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_03-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_04-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_05-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_06-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_07-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_08-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet20_09-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet50-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_01-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_02-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_03-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_04-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_05-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_06-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_07-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_08-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"dataset_splits/ResNet50_09-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # EX5 - PyTorch vs TensorFlow\n",
    "    [\n",
    "        [\n",
    "            \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet20-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "            \"ResNet56-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "            \"ResNet110-cifar10-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet20-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "            \"ResNet56-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "            \"ResNet110-cifar100-idun-A100-TensorFlow-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # EX6 - Increasing Epochs\n",
    "    [\n",
    "        [\n",
    "            \"epochs/ResNet20_e010-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e020-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e030-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e040-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e050-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e075-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e100-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e125-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e150-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e175-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ResNet20_e200-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"epochs/ViTS8_e010-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e020-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e030-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e040-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e050-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e075-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e100-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e125-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e150-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e175-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"epochs/ViTS8_e200-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cvar(dataset, alpha):\n",
    "    # alpha = 0.1 = 90% \n",
    "    # alpha = 0.05 = 95%\n",
    "    # alpha = 0.01 = 99%    \n",
    "\n",
    "    dataset.sort()\n",
    "    var = np.quantile(dataset, alpha)\n",
    "    cvar = dataset[dataset <= var].mean().round(round_digits)\n",
    "    return(cvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kde(data):\n",
    "\n",
    "    max_y = 0  # Initialize a variable to track the maximum y-axis limit across all plots\n",
    "\n",
    "    # Set the number of columns and rows for the subplots\n",
    "    ncols = 2\n",
    "    nrows = math.ceil(len(data) / ncols)  # Calculate the number of rows needed based on the data size\n",
    "\n",
    "    # Dynamically adjust figure size based on the number of rows\n",
    "    figsize = (20, 10 * nrows)\n",
    "\n",
    "    # Create subplots with the determined number of rows and columns\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    fig.tight_layout(pad=7)  # Add padding between subplots\n",
    "\n",
    "    # Ensure `ax` is always treated as a 2D array even if there's only one row or column\n",
    "    ax = np.atleast_2d(ax)\n",
    "\n",
    "    x_mid = np.zeros((nrows, ncols))  # To store the midpoints of x-axis for each subplot\n",
    "    x_range = 0  # Initialize variable to track the largest x-axis range\n",
    "\n",
    "    # Loop through the data and create a KDE plot for each item\n",
    "    for idx, title in enumerate(data):\n",
    "        column = idx % ncols  # Determine the column index for the subplot\n",
    "        row = idx // ncols    # Determine the row index for the subplot\n",
    "\n",
    "        # Plot KDEs for each model in the inner dictionary of `data[title]`\n",
    "        for model, values in data[title].items():\n",
    "            sns.kdeplot(values, ax=ax[row, column], fill=True, label=model)\n",
    "\n",
    "        ax[row, column].legend(fontsize=25)  # Add a legend with larger font size\n",
    "        ax[row, column].set_title(title, fontsize=25)  # Set the title for the subplot\n",
    "        ax[row, column].set_xlabel(\"Top-1 Accuracy\", fontsize=25)  # Label the x-axis\n",
    "        ax[row, column].set_ylabel(\"Density\", fontsize=25)  # Label the y-axis\n",
    "        ax[row, column].tick_params(labelsize=20)  # Adjust tick label sizes\n",
    "\n",
    "        # Get current x-axis limits and calculate the midpoint\n",
    "        x_lim = ax[row, column].get_xlim()\n",
    "        x_mid[row, column] = (x_lim[0] + x_lim[1]) / 2  # Calculate midpoint of the x-axis range\n",
    "\n",
    "        # Update the largest x-axis range found across all plots\n",
    "        if (x_lim[1] - x_lim[0]) > x_range:\n",
    "            x_range = x_lim[1] - x_lim[0]\n",
    "\n",
    "        # Get current y-axis limits and update the global maximum y-axis limit\n",
    "        y_lim = ax[row, column].get_ylim()\n",
    "        if y_lim[1] > max_y:\n",
    "            max_y = y_lim[1]\n",
    "\n",
    "    # Set consistent x and y limits for all subplots\n",
    "    for row_idx in range(nrows):\n",
    "        for col_idx in range(ncols):\n",
    "            # Check if the current subplot corresponds to actual data\n",
    "            if row_idx * ncols + col_idx < len(data):\n",
    "                # Set x-axis limits for each plot, ensuring the range stays within [0, 1]\n",
    "                x_min = x_mid[row_idx, col_idx] - x_range / 2\n",
    "                x_max = x_mid[row_idx, col_idx] + x_range / 2\n",
    "                if x_min < 0:  # Adjust x_min and x_max if necessary to stay within bounds\n",
    "                    x_min = 0\n",
    "                    x_max = x_range\n",
    "                if x_max > 1:\n",
    "                    x_min = 1 - x_range\n",
    "                    x_max = 1\n",
    "\n",
    "                ax[row_idx, col_idx].set_xlim([x_min, x_max])\n",
    "\n",
    "                # Set the y-axis limit for each plot to ensure consistency across all plots\n",
    "                ax[row_idx, col_idx].set_ylim([0, max_y])\n",
    "\n",
    "    plt.show()  # Display the plots\n",
    "\n",
    "    # Save the figure to a file, with the file name based on the first three letters of the title\n",
    "    fig.savefig(title[0:3].lower() + \"_kde.png\", pad_inches=0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxplot(data):\n",
    "    # Set the number of columns and rows for the subplots\n",
    "    ncols = 1\n",
    "    nrows = math.ceil(len(data) / ncols)  # Calculate the number of rows needed based on the data size\n",
    "\n",
    "    # Dynamically adjust figure size based on the number of rows\n",
    "    figsize = (20, 5 * nrows)\n",
    "\n",
    "    # Create subplots with the determined number of rows and columns\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    fig.tight_layout(pad=7)  # Add padding between subplots\n",
    "\n",
    "    # If there's only one subplot, `ax` is not an array, so convert it to a list for consistent handling\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        ax = [ax]\n",
    "    else:\n",
    "        ax = np.ravel(ax)  # Flatten the `ax` array for easier iteration\n",
    "\n",
    "    # Loop through the data and create a box plot for each item\n",
    "    for idx, title in enumerate(data):\n",
    "        sns.boxplot(pd.DataFrame.from_dict(data[title]), ax=ax[idx])\n",
    "        ax[idx].set_title(title, fontsize=16)               # Set the title for each subplot\n",
    "        ax[idx].set_ylabel(\"Top-1 Accuracy\", fontsize=16)   # Label the y-axis\n",
    "        ax[idx].tick_params(labelsize=14)                   # Adjust tick label size\n",
    "\n",
    "        # Hide top and right spines for better aesthetics\n",
    "        ax[idx].spines[\"top\"].set_visible(False)\n",
    "        ax[idx].spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(title[0:3].lower() + \"_box.png\", pad_inches=0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cvar(data):\n",
    "    # Set the number of columns and rows for the subplots\n",
    "    # 2 columns and as many rows as needed to fit all the data\n",
    "    ncols = 2\n",
    "    nrows = 0\n",
    "\n",
    "    # Calculate the number of rows needed based on the data size\n",
    "    # Iterate over each title in the data and sum up the number of rows needed\n",
    "    for idx, title in enumerate(data):\n",
    "        runs = len(data[title])  # Number of runs associated with the current title\n",
    "        nrows += math.ceil(runs / ncols)  # Calculate the number of rows for the current title\n",
    "\n",
    "    # Initialize variables to track the maximum y-axis limit and x-axis range across all plots\n",
    "    max_y = 0  # Maximum y-axis value\n",
    "    x_mid = np.zeros((nrows, ncols))  # To store the midpoints of the x-axis for each subplot\n",
    "    x_range = 0  # Largest x-axis range across all plots\n",
    "\n",
    "    # Set figure size based on the number of rows\n",
    "    figsize = (20, 5 * nrows)  # Adjust width and height of the figure dynamically\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)  # Create subplots\n",
    "    fig.tight_layout(pad=7)  # Adjust padding between plots\n",
    "\n",
    "    # Uncomment the following line to add a global title (if necessary)\n",
    "    #fig.suptitle(title, fontsize=25)\n",
    "\n",
    "    plt.legend(fontsize='x-large', title_fontsize='40')  # Set legend font sizes\n",
    "\n",
    "    row_run_offset = 0  # To manage row indices across different runs\n",
    "\n",
    "    # Loop through each title in the data and generate plots\n",
    "    for idx, title in enumerate(data):\n",
    "        \n",
    "        # Iterate through each run for the current title\n",
    "        for idy, run_name in enumerate(data[title]):\n",
    "            # Calculate the subplot's row and column indices\n",
    "            column = idy % ncols  # Column index (modulus ensures alternating between columns)\n",
    "            row = (idy // ncols) + row_run_offset  # Row index (adjusted by the offset for each title)\n",
    "\n",
    "            # Calculate the mean and CVaR (Conditional Value at Risk) for the current run\n",
    "            dataset_mean = data[title][run_name].mean()\n",
    "            cvar = calculate_cvar(data[title][run_name], cvar_alpha)  # Custom function to calculate CVaR\n",
    "\n",
    "            # Create a Kernel Density Estimate (KDE) plot for the run's data\n",
    "            sns.kdeplot(data[title][run_name], \n",
    "                        ax=ax[row, column], \n",
    "                        fill=True, \n",
    "            )\n",
    "\n",
    "            # Add vertical lines for the mean and CVaR\n",
    "            ax[row, column].axvline(dataset_mean, color='red', linestyle='solid', \n",
    "                                    label=\"Mean: %.2f%% \" % (dataset_mean * 100))  # Red solid line for the mean\n",
    "            ax[row, column].axvline(cvar, color='red', linestyle='dashed', \n",
    "                                    label=\"CVaR: %.2f%% \" % (cvar * 100))  # Red dashed line for CVaR\n",
    "\n",
    "            # Add legend to the current plot\n",
    "            ax[row, column].legend(fontsize=25)\n",
    "\n",
    "            # Set plot title and axis labels\n",
    "            ax[row, column].set_title(run_name, fontsize=25)  # Set the run name as the plot title\n",
    "            ax[row, column].set_xlabel(\"Top-1 Accuracy\", fontsize=25)  # Label for x-axis\n",
    "            ax[row, column].set_ylabel(\"Density\", fontsize=25)  # Label for y-axis\n",
    "            \n",
    "            ax[row, column].tick_params(labelsize=20)  # Set tick size for better readability\n",
    "\n",
    "            # Get current x-axis limits and calculate the midpoint\n",
    "            x_lim = ax[row, column].get_xlim()\n",
    "            x_mid[row, column] = (x_lim[0] + x_lim[1]) / 2  # Calculate and store the midpoint of the x-axis range\n",
    "\n",
    "            # Update the largest x-axis range found across all plots\n",
    "            if (x_lim[1] - x_lim[0]) > x_range:\n",
    "                x_range = x_lim[1] - x_lim[0]\n",
    "\n",
    "            # Get current y-axis limits and update the global maximum y-axis limit\n",
    "            y_lim = ax[row, column].get_ylim()\n",
    "            if y_lim[1] > max_y:\n",
    "                max_y = y_lim[1]\n",
    "\n",
    "        # After processing all runs for the current title, update row_run_offset to start on a new row\n",
    "        row_run_offset = row + 1\n",
    "\n",
    "    # Ensure consistent x and y limits across all subplots\n",
    "    for row_idx in range(nrows):\n",
    "        for col_idx in range(ncols):\n",
    "\n",
    "            # Hide empty graphs (subplots that have no data)\n",
    "            if ax[row_idx, col_idx].get_xlim() == (0.0, 1.0):\n",
    "                ax[row_idx, col_idx].axis('off')  # Turn off axis for empty plots\n",
    "                continue\n",
    "\n",
    "            # Set x-axis limits to be consistent across all subplots\n",
    "            x_min = x_mid[row_idx, col_idx] - x_range / 2\n",
    "            x_max = x_mid[row_idx, col_idx] + x_range / 2\n",
    "            if x_min < 0:  # Ensure x_min is within bounds\n",
    "                x_min = 0\n",
    "                x_max = x_range\n",
    "            if x_max > 1:  # Ensure x_max is within bounds\n",
    "                x_min = 1 - x_range\n",
    "                x_max = 1\n",
    "\n",
    "            # Apply consistent x-axis limits\n",
    "            ax[row_idx, col_idx].set_xlim([x_min, x_max])\n",
    "\n",
    "            # Set consistent y-axis limits across all subplots\n",
    "            ax[row_idx, col_idx].set_ylim([0, max_y])\n",
    "\n",
    "    # Display the figure\n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure with the title as part of the filename\n",
    "    fig.savefig(title[0:3].lower() + \"_cvar.png\", pad_inches=0.1, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary statistics so they can be saved to a CSV file\n",
    "summary_statistics = []\n",
    "\n",
    "for idx, experiment_list in enumerate(experiments_by_model_and_dataset):\n",
    "\n",
    "    experiment_data = {}\n",
    "\n",
    "    experiment_number = \"EX\" + str(idx + 1) + \":\"\n",
    "    \n",
    "    for experiments in experiment_list:\n",
    "        # Start the title with the experiment number\n",
    "        title = experiment_number\n",
    "\n",
    "        # Include model in title\n",
    "        if \"resnet\" in experiments[0].lower():\n",
    "            title += \" ResNet\"\n",
    "        elif \"vit\" in experiments[0].lower():\n",
    "            title += \" ViT\"\n",
    "\n",
    "        # Save the individual results for the plots\n",
    "        results_values = {}\n",
    "\n",
    "        # Loop through the individual experiments\n",
    "        for experiment in experiments:\n",
    "            df = pd.read_csv(base_directory + experiment)\n",
    "\n",
    "            # Get the 100 results\n",
    "            results = df[results_column].values\n",
    "            # Calculate the summary statistics\n",
    "            dist_mean = np.mean(results).round(round_digits)\n",
    "            dist_median = np.median(results).round(round_digits)\n",
    "            dist_min = np.min(results).round(round_digits)\n",
    "            dist_max = np.max(results).round(round_digits)\n",
    "            dist_range = (dist_max - dist_min).round(round_digits)\n",
    "            q_1 = np.quantile(results, 0.25).round(round_digits)\n",
    "            q_3 = np.quantile(results, 0.75).round(round_digits)\n",
    "            dist_std = np.std(results).round(round_digits)\n",
    "            c_v = variation(results).round(round_digits)\n",
    "            cvar = calculate_cvar(results, cvar_alpha)\n",
    "            skewness = skew(results).round(round_digits)\n",
    "            k_value = kurtosis(results).round(round_digits)\n",
    "\n",
    "            # Get the model and dataset from the experiment name\n",
    "            dataset = experiment.split(\"-\")[1]\n",
    "            model = experiment.split(\"-\")[0]\n",
    "\n",
    "            # Add the dataset to the title if it is not already there\n",
    "            if dataset not in title:\n",
    "                title = title + \" \" + dataset\n",
    "\n",
    "            # Add whether the model is pretrained or not for the ViT 16 models\n",
    "            if \"vit\" in model.lower() and \"16\" in model.lower():\n",
    "                if \"pretrained\" in experiment:\n",
    "                    model += \" (Pretrained)\"\n",
    "                    if \"pretrained\" not in title.lower():\n",
    "                        title += \" (Pretrained)\"\n",
    "                else:\n",
    "                    model += \" (Random)\"\n",
    "                    if \"random\" not in title.lower():\n",
    "                        title += \" (Random)\"\n",
    "\n",
    "            # Remove the subdirectory name for the EX3 models\n",
    "            if \"ex3\" in title.lower():\n",
    "                model = model.replace(\"learning_rate/\", \"\")\n",
    "\n",
    "            # Remove the subdirectory name for the EX4 models        \n",
    "            if \"ex4\" in title.lower():\n",
    "                model = model.replace(\"dataset_splits/\", \"\")\n",
    "\n",
    "            # Add whether the model is TensorFlow or PyTorch for the EX5 experiments\n",
    "            if \"ex5\" in title.lower():\n",
    "                if \"tensorflow\" in experiment.lower():\n",
    "                    model += \" (TensorFlow)\"\n",
    "                else:\n",
    "                    model += \" (PyTorch)\"\n",
    "\n",
    "            # Remove the subdirectory name for the EX6 models        \n",
    "            if \"ex6\" in title.lower():\n",
    "                model = model.replace(\"epochs/\", \"\")\n",
    "\n",
    "            # Save the results for the plot\n",
    "            results_values[model] = results\n",
    "\n",
    "            # Save the summary statistics\n",
    "            summary_statistics.append([dataset, model, dist_mean, dist_median, dist_min, dist_max, dist_range, q_1, q_3, dist_std, c_v, cvar, skewness, k_value])\n",
    "\n",
    "        # Save the results for the experiment\n",
    "        experiment_data[title] = results_values\n",
    "\n",
    "    # Plot the results for the experiment as a KDE histogram\n",
    "    save_kde(experiment_data)\n",
    "    save_boxplot(experiment_data)\n",
    "    save_cvar(experiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_df = pd.DataFrame(summary_statistics, columns=[\"Dataset\", \"Model\", \"Mean\", \"Median\", \"Min\", \"Max\", \"Range\", \"25th_percentile\", \"75th_percentile\", \"Std\", \"Coefficient of Variation\", \"CVaR 95%\", \"Skewness\", \"Kertosis\"])\n",
    "summary_statistics_df.to_csv(\"image_summary_statistics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
